{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, Conv2D, MaxPooling2D, Flatten,Activation,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input,EfficientNetB0\n",
    "\n",
    "from tensorflow.keras import callbacks as cb\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth( device=gpu, enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 40 classes=source 36 + target 4 classes\n"
     ]
    }
   ],
   "source": [
    "all_classes = glob('../data/orl_faces/*')\n",
    "source_classes,target_classes=train_test_split(all_classes,test_size=0.1)\n",
    "sorce_len=len(source_classes)\n",
    "target_len=len(target_classes)\n",
    "print(f\"total {len(all_classes)} classes=source {sorce_len} + target {target_len} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,H,CH = 64,64,1\n",
    "def read_pgm(filename):\n",
    "    byteorder='>'\n",
    "    #first we read the image, as a raw file to the buffer\n",
    "    with open(filename, 'rb') as f:\n",
    "        buffer = f.read()\n",
    "    \n",
    "    #using regex, we extract the header, width, height and maxval of the image\n",
    "    header, width, height, maxval = re.search(\n",
    "        b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "    \n",
    "    #then we convert the image to numpy array using np.frombuffer which interprets buffer as one dimensional array\n",
    "    return np.frombuffer(buffer,\n",
    "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
    "                            count=int(width)*int(height),\n",
    "                            offset=len(header)\n",
    "                            ).reshape((int(height), int(width)))\n",
    "def load_img(path, width = W):\n",
    "    img = read_pgm(path.numpy().decode()).astype(np.float32)/255.\n",
    "    shape_dst = np.min(img.shape[:2])\n",
    "    oh = (img.shape[0] - shape_dst) // 2\n",
    "    ow = (img.shape[1] - shape_dst) // 2\n",
    "    center_square = np.array([width,width])// 2\n",
    "    new_size=(width,width)\n",
    "    \n",
    "    # cropping + resize\n",
    "    img = img[oh:oh + shape_dst, ow:ow + shape_dst]\n",
    "    img=np.expand_dims(cv2.resize(img, new_size),-1)\n",
    "    return tf.constant(img)\n",
    "SUFFIX='.pgm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAYS = 3\n",
    "SHOTS=5\n",
    "QUERIES=2\n",
    "BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(glob(sdir+'/*'+SUFFIX)) for sdir in source_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 36 + target 4 classes\n"
     ]
    }
   ],
   "source": [
    "## exclude classes with too few examples\n",
    "source_classes=[sdir for sdir in source_classes if len(glob(sdir+'/*'+SUFFIX))>SHOTS+QUERIES]\n",
    "\n",
    "sorce_len=len(source_classes)\n",
    "print(f\"source {sorce_len} + target {target_len} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(glob(sdir+'/*'+SUFFIX)) for sdir in source_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_fun=lambda string: tf.py_function(func=load_img,inp=[string], Tout=tf.float32)\n",
    "source_sub = [\n",
    "    tf.data.Dataset.list_files(sc+'/*'+SUFFIX, shuffle=True)\n",
    "    .map(map_fun)\n",
    "    for sc in source_classes\n",
    "]\n",
    "target_sub = [\n",
    "    tf.data.Dataset.list_files(sc+'/*'+SUFFIX, shuffle=True)\n",
    "    .map(map_fun)\n",
    "    for sc in target_classes\n",
    "]\n",
    "def gen(all_sub):\n",
    "    supports = []\n",
    "    querys = []\n",
    "    order=np.random.permutation(len(all_sub))\n",
    "    for tasks in range(len(all_sub)//WAYS):\n",
    "        picked=[all_sub[tt] for tt in order[WAYS*tasks:WAYS*(tasks+1)]]\n",
    "        support = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        sub.batch(SHOTS).prefetch(SHOTS)\n",
    "                    )\n",
    "                    ) for sub in picked\n",
    "            ]\n",
    "            , axis=0)\n",
    "        idxs=np.random.choice(range(WAYS), size=QUERIES, replace=False)\n",
    "        query = tf.concat(\n",
    "            [\n",
    "                next(\n",
    "                    iter(\n",
    "                        picked[idx].batch(1).prefetch(1)\n",
    "                    )\n",
    "                    ) for idx in idxs\n",
    "            ]\n",
    "            , axis=0)\n",
    "        yield tf.concat([support, query], axis=0), tuple([keras.utils.to_categorical(idx,num_classes=WAYS) for idx in idxs])\n",
    "def gen_source():\n",
    "    return gen(source_sub)\n",
    "def gen_target():\n",
    "    return gen(target_sub)\n",
    "\n",
    "\n",
    "data_source = tf.data.Dataset.from_generator(gen_source,\n",
    "                                    output_types=(tf.float32,tuple([tf.float32]*QUERIES)),\n",
    "                                    output_shapes=((WAYS*SHOTS+QUERIES,W,H,CH),tuple([WAYS]*QUERIES))).batch(BATCH_SIZE)\n",
    "data_target = tf.data.Dataset.from_generator(gen_target,\n",
    "                                    output_types=(tf.float32,tuple([tf.float32]*QUERIES)),\n",
    "                                    output_shapes=((WAYS*SHOTS+QUERIES,W,H,CH),tuple([WAYS]*QUERIES))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(input_shape):\n",
    "    convnet = Sequential()\n",
    "    for i in range(4):\n",
    "        convnet.add(Conv2D(64,(3,3),padding='valid',input_shape=input_shape))\n",
    "        convnet.add(BatchNormalization())\n",
    "        convnet.add(Activation('relu'))\n",
    "        convnet.add(MaxPooling2D())\n",
    "    convnet.add(Flatten())\n",
    "    return convnet\n",
    "# def pretrain_net(input_shape):\n",
    "#     base_model = EfficientNetB0(input_shape=(W,H,CH),weights=\"imagenet\", include_top=False)\n",
    "#     x_in=Input(shape=(W,H,CH))\n",
    "#     x=preprocess_input(x_in)\n",
    "#     out=Flatten()(base_model(x))\n",
    "#     model = Model(inputs=x_in, outputs=out)\n",
    "#     return model\n",
    "def euclidean_distance(f_1,f_2):\n",
    "    \"\"\"\n",
    "    Euclidean distance loss\n",
    "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "    :param y_true: TensorFlow/Theano tensor\n",
    "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(f_1 - f_2), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dim = (W,H,CH)\n",
    "base_network = conv_net(base_dim)\n",
    "# Query feature\n",
    "x_in=Input(shape=(WAYS*SHOTS+QUERIES,W,H,CH))\n",
    "latent_s=[base_network(x_in[:,ii]) for ii in range(WAYS*SHOTS)]\n",
    "latent_q=[base_network(x_in[:,WAYS*SHOTS+ii]) for ii in range(QUERIES)]\n",
    "\n",
    "y=list()\n",
    "for qq in range(QUERIES):\n",
    "    dist_scores=list()\n",
    "    for ww in range(WAYS):\n",
    "        latent_proto=tf.reduce_mean(tf.stack(latent_s[ww*SHOTS:(ww+1)*SHOTS],axis=-1),axis=-1)\n",
    "        dist_avg=euclidean_distance(latent_q[qq],latent_proto)\n",
    "        dist_scores.append(dist_avg)\n",
    "    y.append(tf.nn.softmax(-tf.stack(dist_scores,axis=-1),axis=-1))\n",
    "\n",
    "model = Model(inputs=x_in, outputs=tuple(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "def scheduler(epoch):\n",
    "    global lr\n",
    "    if epoch % 3 == 0:\n",
    "        lr /= 2\n",
    "    return lr\n",
    "reduce_lr = cb.ReduceLROnPlateau(monitor='loss', factor=0.4,patience=2, min_lr=1e-8)\n",
    "lr_sched = cb.LearningRateScheduler(scheduler)\n",
    "tensorboard = cb.TensorBoard()\n",
    "opt = tf.keras.optimizers.Adam(lr=0.002)\n",
    "model.compile(loss=CategoricalCrossentropy(), optimizer=opt, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "      1/Unknown - 0s 93us/step - loss: 0.1186 - tf_op_layer_Softmax_loss: 0.0777 - tf_op_layer_Softmax_1_loss: 0.0409 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "3/3 [==============================] - 1s 360ms/step - loss: 0.1803 - tf_op_layer_Softmax_loss: 0.0587 - tf_op_layer_Softmax_1_loss: 0.1215 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 1s 257ms/step - loss: 0.2746 - tf_op_layer_Softmax_loss: 0.1840 - tf_op_layer_Softmax_1_loss: 0.0905 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 1s 269ms/step - loss: 0.3646 - tf_op_layer_Softmax_loss: 0.1290 - tf_op_layer_Softmax_1_loss: 0.2356 - tf_op_layer_Softmax_categorical_accuracy: 0.9167 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 1s 264ms/step - loss: 0.1601 - tf_op_layer_Softmax_loss: 0.0427 - tf_op_layer_Softmax_1_loss: 0.1175 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 1s 262ms/step - loss: 0.1061 - tf_op_layer_Softmax_loss: 0.0287 - tf_op_layer_Softmax_1_loss: 0.0773 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 1s 261ms/step - loss: 0.1646 - tf_op_layer_Softmax_loss: 0.0833 - tf_op_layer_Softmax_1_loss: 0.0813 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 1s 257ms/step - loss: 0.1761 - tf_op_layer_Softmax_loss: 0.0415 - tf_op_layer_Softmax_1_loss: 0.1346 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.2063 - tf_op_layer_Softmax_loss: 0.1198 - tf_op_layer_Softmax_1_loss: 0.0865 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 1s 264ms/step - loss: 0.1912 - tf_op_layer_Softmax_loss: 0.0521 - tf_op_layer_Softmax_1_loss: 0.1391 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 1s 260ms/step - loss: 0.1770 - tf_op_layer_Softmax_loss: 0.0532 - tf_op_layer_Softmax_1_loss: 0.1238 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.0833 - tf_op_layer_Softmax_loss: 0.0273 - tf_op_layer_Softmax_1_loss: 0.0560 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 1s 269ms/step - loss: 0.1167 - tf_op_layer_Softmax_loss: 0.0259 - tf_op_layer_Softmax_1_loss: 0.0908 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 1s 255ms/step - loss: 0.1136 - tf_op_layer_Softmax_loss: 0.0375 - tf_op_layer_Softmax_1_loss: 0.0761 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 1s 264ms/step - loss: 0.2052 - tf_op_layer_Softmax_loss: 0.0985 - tf_op_layer_Softmax_1_loss: 0.1067 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.1864 - tf_op_layer_Softmax_loss: 0.0912 - tf_op_layer_Softmax_1_loss: 0.0951 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 1s 255ms/step - loss: 0.1071 - tf_op_layer_Softmax_loss: 0.0580 - tf_op_layer_Softmax_1_loss: 0.0491 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 0.0722 - tf_op_layer_Softmax_loss: 0.0308 - tf_op_layer_Softmax_1_loss: 0.0414 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 1s 266ms/step - loss: 0.2154 - tf_op_layer_Softmax_loss: 0.1248 - tf_op_layer_Softmax_1_loss: 0.0906 - tf_op_layer_Softmax_categorical_accuracy: 0.9167 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 1s 262ms/step - loss: 0.1098 - tf_op_layer_Softmax_loss: 0.0729 - tf_op_layer_Softmax_1_loss: 0.0369 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 1s 255ms/step - loss: 0.1219 - tf_op_layer_Softmax_loss: 0.0265 - tf_op_layer_Softmax_1_loss: 0.0954 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 1s 254ms/step - loss: 0.1287 - tf_op_layer_Softmax_loss: 0.0880 - tf_op_layer_Softmax_1_loss: 0.0407 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 0.0821 - tf_op_layer_Softmax_loss: 0.0638 - tf_op_layer_Softmax_1_loss: 0.0183 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 1s 257ms/step - loss: 0.2739 - tf_op_layer_Softmax_loss: 0.1679 - tf_op_layer_Softmax_1_loss: 0.1060 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 1s 261ms/step - loss: 0.3081 - tf_op_layer_Softmax_loss: 0.2232 - tf_op_layer_Softmax_1_loss: 0.0849 - tf_op_layer_Softmax_categorical_accuracy: 0.9167 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 0.0949 - tf_op_layer_Softmax_loss: 0.0349 - tf_op_layer_Softmax_1_loss: 0.0600 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 1s 267ms/step - loss: 0.0301 - tf_op_layer_Softmax_loss: 0.0115 - tf_op_layer_Softmax_1_loss: 0.0185 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 1s 262ms/step - loss: 0.1903 - tf_op_layer_Softmax_loss: 0.1203 - tf_op_layer_Softmax_1_loss: 0.0700 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 1s 264ms/step - loss: 0.2507 - tf_op_layer_Softmax_loss: 0.0784 - tf_op_layer_Softmax_1_loss: 0.1723 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 1s 260ms/step - loss: 0.1810 - tf_op_layer_Softmax_loss: 0.0210 - tf_op_layer_Softmax_1_loss: 0.1599 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 1s 267ms/step - loss: 0.1959 - tf_op_layer_Softmax_loss: 0.1357 - tf_op_layer_Softmax_1_loss: 0.0603 - tf_op_layer_Softmax_categorical_accuracy: 0.9167 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.2182 - tf_op_layer_Softmax_loss: 0.0557 - tf_op_layer_Softmax_1_loss: 0.1625 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 1s 266ms/step - loss: 0.2320 - tf_op_layer_Softmax_loss: 0.1899 - tf_op_layer_Softmax_1_loss: 0.0421 - tf_op_layer_Softmax_categorical_accuracy: 0.9167 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 1s 260ms/step - loss: 0.3258 - tf_op_layer_Softmax_loss: 0.0466 - tf_op_layer_Softmax_1_loss: 0.2792 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 0.9167\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 1s 255ms/step - loss: 0.0494 - tf_op_layer_Softmax_loss: 0.0184 - tf_op_layer_Softmax_1_loss: 0.0311 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 1s 254ms/step - loss: 0.1573 - tf_op_layer_Softmax_loss: 0.0518 - tf_op_layer_Softmax_1_loss: 0.1055 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 0.0649 - tf_op_layer_Softmax_loss: 0.0198 - tf_op_layer_Softmax_1_loss: 0.0450 - tf_op_layer_Softmax_categorical_accuracy: 1.0000 - tf_op_layer_Softmax_1_categorical_accuracy: 1.0000\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5d08b223ae34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %%time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_sched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "model.fit(data_source, epochs=1000, verbose=1,workers=4, callbacks=[reduce_lr,lr_sched, tensorboard],validation_data=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
